aprender a debbugar cod



## Ol√° eu sou o R√™ üëã






- üî≠ Hoje trabalho na assessoria @Bradesco - Ultra High Value. (UHV)
- üå± Estudando automa√ß√£o de sistemas com Python. (Udemy)
- üå± Cursando ensino superior em √Ånalise e desenvolvimento de sistemas.(FMU)
- üì´ Contate-me no e-mail: "Renatofrancelino17@hotmail.com"
- üòÑ Pronome: ele/dele.





Microsoft Windows [vers√£o 10.0.26200.7462]
(c) Microsoft Corporation. Todos os direitos reservados.

C:\Users\Renato\Desktop\estudo\Redevneyjr>git add .

C:\Users\Renato\Desktop\estudo\Redevneyjr>git commit -m "Atualizando Read.me"
[main 7e1cdcc] Atualizando Read.me



PS C:\Users\Renato\Desktop\estudo\curso_automacao_python> git add .
PS C:\Users\Renato\Desktop\estudo\curso_automacao_python> git commit -m "Atualizando Read.me"


pesquisar: 

codar em python:

lista 
tuplas 
condicionais








  - python -> back





origem dos dados 

o que eu vou com esses dados 
 analises
  limpeza
 - excel







o que eu vou fazer com os dados limpos 
onde demonstrar essa informa√ß√£o
- power bi 



"analise de sentimento de produtos (e-commerce)"






preciso montar um projeto para portfolio porem eu quero fazer uso do py, GitHub para versionamento e tb quero expor as analises de projeto as analises em power bi , preciso que voc√™ gere as ideias onde eu use py no back end e o power bi




como atribuir acesso ao meu reposit√≥rio para trabalharmos juntos no git hub 

abri o chrome ate o mercado livre de forma autom√°tica


2 semanas.










1 - 1. An√°lise de Sentimento de Produtos (E-commerce)
Neste projeto, voc√™ foca em NLP (Processamento de Linguagem Natural). O diferencial aqui √© transformar texto subjetivo em dados quantitativos para o dashboard.

O Back-end (Python): Utilize bibliotecas como BeautifulSoup ou Selenium para fazer um web scraping de reviews de um site (ou use um dataset do Kaggle). Use o TextBlob ou VADER para atribuir uma nota de sentimento (positivo, negativo, neutro) a cada coment√°rio.

Versionamento (GitHub): Suba o script de raspagem e o notebook de an√°lise explorat√≥ria.

O Dashboard (Power BI): Mostre a evolu√ß√£o do sentimento ao longo do tempo, as palavras mais citadas (Word Cloud) e a correla√ß√£o entre a nota do produto e o sentimento do texto.


2- Como estruturar o seu GitHub para esse projeto
Para um Analista de Dados, o README √© o seu cart√£o de visitas. Estruture assim:

T√≠tulo do Projeto: Ex: Pipeline de Previs√£o de Demanda com Python & Power BI.

Problema de Neg√≥cio: Explique por que esse projeto existe (ex: "Empresas perdem X% de lucro por falta de estoque").

Tecnologias: √çcones do Python, Pandas, Power BI e GitHub.

O Fluxo de Dados: Descreva como o dado sai do Python e chega no BI.

Insights Extra√≠dos: Liste 3 conclus√µes que o dashboard permite tirar.

3 - Dica de Ouro: O "Bot√£o M√°gico"
Se voc√™ quiser impressionar de verdade, em vez de apenas importar um arquivo est√°tico, tente salvar o resultado do Python em um banco de dados leve como SQLite ou uma planilha no Google Sheets via API. O Power BI ent√£o se conecta a essa fonte "viva".

4 - O Fluxograma do Projeto
Antes de escrever c√≥digo, voc√™ precisa entender o caminho que o dado percorre.

Coleta: O Selenium abre o navegador e "copia" as avalia√ß√µes dos clientes.

Limpeza: O Python (Pandas) remove sujeiras (emojis, links, pontos).

Intelig√™ncia: O Python analisa se o texto √© bom ou ruim.

Entrega: O Python gera um arquivo Excel/CSV.

Visualiza√ß√£o: O Power BI l√™ esse arquivo e cria os gr√°ficos.

5- 





analise_de_sentimento_de_e-commerce












recolher o c√≥digo atualizado com o git pull


xpath composto para puxar arquivo














montar o xpath

alt="Desculpe! Algo deu errado. Tente novamente ou volte para a p√°gina inicial da Amazon."




'Patrocinado\nReivindicada Pelo Mafioso\npor Ariela Pereira | 15 mar. 2025\n4,6\n(2,6 mil)\neBook Kindle\nR$0\n00\nGr√°tis com assinatura Kindle Unlimited Saiba mais\nDispon√≠vel instantaneamente\nOu R$ 5,99 para comprar'






from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import time
import csv

# Configura√ß√µes do navegador
chrome_options = Options()
chrome_options.add_argument("--window-size=1280,800")
chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
navegador = webdriver.Chrome(options=chrome_options)
wait = WebDriverWait(navegador, 10)

# Fun√ß√£o para atualizar a p√°gina com at√© 2 tentativas
def atualizar_pagina(url=None, tentativas=2):
    for tentativa in range(tentativas):
        try:
            if url:
                navegador.get(url)
            else:
                navegador.refresh()
            time.sleep(3)
            wait.until(
                EC.presence_of_all_elements_located((By.XPATH, '//div[@data-component-type="s-search-result"]'))
            )
            print(f"‚úÖ P√°gina carregada na tentativa {tentativa+1}")
            return True
        except:
            print(f"‚ö†Ô∏è Tentativa {tentativa+1} falhou, tentando novamente...")
    print("‚ùå N√£o foi poss√≠vel carregar a p√°gina ap√≥s 2 tentativas.")
    return False

# Fun√ß√£o para extrair t√≠tulo com m√∫ltiplos seletores e fallback
def extrair_titulo(livro):
    seletores = [
        './/span[@class="a-size-medium a-color-base a-text-normal"]',
        './/span[@class="a-size-base-plus a-color-base a-text-normal"]',
        './/h2/a/span',
        './/a[@class="a-link-normal s-no-outline"]/span'
    ]
    for seletor in seletores:
        try:
            elemento = livro.find_element(By.XPATH, seletor)
            titulo = elemento.text.strip()
            if titulo:
                return titulo
        except:
            continue
    try:
        imagem = livro.find_element(By.XPATH, './/img[@class="s-image"]')
        titulo = imagem.get_attribute("alt").strip()
        if titulo:
            return titulo
    except:
        pass
    return "T√≠tulo n√£o encontrado"

# URL inicial
url_base = "https://www.amazon.com.br/s?k=freud&i=stripbooks"
navegador.get(url_base)

# Tenta carregar os resultados
try:
    livros = wait.until(
        EC.presence_of_all_elements_located((By.XPATH, '//div[@data-component-type="s-search-result"]'))
    )
except:
    print("‚ö†Ô∏è P√°gina bloqueada, atualizando...")
    if atualizar_pagina(url_base):
        livros = wait.until(
            EC.presence_of_all_elements_located((By.XPATH, '//div[@data-component-type="s-search-result"]'))
        )
    else:
        livros = []

# Pega apenas os 5 primeiros
livros = livros[:5]

aba_principal = navegador.current_window_handle
resultados = []

for contador, livro in enumerate(livros, start=1):
    titulo = extrair_titulo(livro)

    try:
        nota = livro.find_element(By.XPATH, './/span[@class="a-icon-alt"]').text
    except:
        nota = "Sem avalia√ß√£o"

    try:
        link = livro.find_element(By.XPATH, './/a[@class="a-link-normal s-no-outline"]').get_attribute("href")
    except:
        link = "Sem link"

    comentarios_extraidos = []

    if link != "Sem link":
        navegador.execute_script("window.open(arguments[0]);", link)
        navegador.switch_to.window(navegador.window_handles[-1])
        try:
            comentarios = WebDriverWait(navegador, 5).until(
                EC.presence_of_all_elements_located((By.XPATH, '//span[@data-hook="review-body"]'))
            )
            for comentario in comentarios[:3]:
                comentarios_extraidos.append(comentario.text.strip())
        except:
            print("‚ö†Ô∏è Coment√°rios bloqueados, atualizando...")
            if atualizar_pagina(link):
                try:
                    comentarios = WebDriverWait(navegador, 5).until(
                        EC.presence_of_all_elements_located((By.XPATH, '//span[@data-hook="review-body"]'))
                    )
                    for comentario in comentarios[:3]:
                        comentarios_extraidos.append(comentario.text.strip())
                except:
                    comentarios_extraidos.append("Sem coment√°rios dispon√≠veis.")
            else:
                comentarios_extraidos.append("Sem coment√°rios dispon√≠veis.")
        navegador.close()
        navegador.switch_to.window(aba_principal)

    if "5" in nota or "4" in nota:
        avaliacao = "BOM livro"
    elif "3" in nota:
        avaliacao = "REGULAR"
    else:
        avaliacao = "RUIM ou sem dados"

    resultados.append({
        "T√≠tulo": titulo,
        "Nota": nota,
        "Link": link,
        "Coment√°rios": "; ".join(comentarios_extraidos) if comentarios_extraidos else "Sem coment√°rios",
        "Avalia√ß√£o": avaliacao
    })

    print(f"\nLivro {contador}: {titulo}")
    print(f"Nota m√©dia: {nota}")
    print(f"Link: {link}")
    print(f"Coment√°rios: {comentarios_extraidos if comentarios_extraidos else 'Sem coment√°rios'}")
    print(f"Avalia√ß√£o: {avaliacao}")

navegador.quit()

# Exporta para CSV
with open("livros.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["T√≠tulo", "Nota", "Link", "Coment√°rios", "Avalia√ß√£o"])
    writer.writeheader()
    writer.writerows(resultados)

print("üìÇ Resultados salvos em 'livros.csv'")












2


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import time
import csv

# Configura√ß√µes do navegador
chrome_options = Options()
chrome_options.add_argument("--window-size=1280,800")
chrome_options.add_argument("--disable-blink-features=AutomationControlled")
chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
chrome_options.add_experimental_option('useAutomationExtension', False)
chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

navegador = webdriver.Chrome(options=chrome_options)
wait = WebDriverWait(navegador, 10)

# Fun√ß√£o para atualizar a p√°gina com at√© 4 tentativas
def atualizar_pagina(url=None, tentativas=4):
    for tentativa in range(tentativas):
        try:
            if url:
                navegador.get(url)
            else:
                navegador.refresh()
            wait.until(
                EC.presence_of_all_elements_located((By.XPATH, '//div[@data-component-type="s-search-result"]'))
            )
            print(f"‚úÖ P√°gina carregada na tentativa {tentativa+1}")
            return True
        except:
            print(f"‚ö†Ô∏è Tentativa {tentativa+1} falhou, tentando novamente...")
            time.sleep(3)
    print("‚ùå N√£o foi poss√≠vel carregar a p√°gina ap√≥s 4 tentativas.")
    return False

# Fun√ß√£o corrigida para extrair t√≠tulo
def extrair_titulo(livro):
    try:
        # O t√≠tulo geralmente est√° dentro de h2 > a > span
        elemento = livro.find_element(By.XPATH, './/h2/a/span')
        titulo = elemento.text.strip()
        if titulo:
            return titulo
    except:
        pass
    try:
        # Fallback: atributo alt da imagem
        imagem = livro.find_element(By.XPATH, './/img[@class="s-image"]')
        titulo = imagem.get_attribute("alt").strip()
        if titulo:
            return titulo
    except:
        pass
    return "T√≠tulo n√£o encontrado"

# Fun√ß√£o para extrair nota
def extrair_nota(livro):
    try:
        nota = livro.find_element(By.XPATH, './/span[@class="a-icon-alt"]').text
        return nota
    except:
        return "Sem avalia√ß√£o"

# Fun√ß√£o para extrair coment√°rios
def extrair_comentarios(link):
    comentarios_extraidos = []
    navegador.get(link)
    try:
        comentarios = WebDriverWait(navegador, 5).until(
            EC.presence_of_all_elements_located((By.XPATH, '//span[@data-hook="review-body"]'))
        )
        for comentario in comentarios[:3]:
            texto = comentario.text.strip()
            if texto:
                comentarios_extraidos.append(texto)
    except:
        comentarios_extraidos.append("Sem coment√°rios dispon√≠veis.")
    return comentarios_extraidos if comentarios_extraidos else ["Sem coment√°rios dispon√≠veis."]

# Fun√ß√£o para recolher nota atribu√≠da pelo usu√°rio
def nota_usuario(titulo):
    while True:
        try:
            nota = int(input(f"üìò D√™ uma nota de 1 a 5 para o livro '{titulo}': "))
            if 1 <= nota <= 5:
                return nota
            else:
                print("Digite um n√∫mero entre 1 e 5.")
        except ValueError:
            print("Entrada inv√°lida. Digite apenas n√∫meros.")

# URL inicial
url_base = "https://www.amazon.com.br/s?k=freud&i=stripbooks"
navegador.get(url_base)

# Carregar resultados
if not atualizar_pagina(url_base):
    livros = []
else:
    livros = wait.until(
        EC.presence_of_all_elements_located((By.XPATH, '//div[@data-component-type="s-search-result"]'))
    )

# Pega apenas os 5 primeiros
livros = livros[:5]

resultados = []

for contador, livro in enumerate(livros, start=1):
    titulo = extrair_titulo(livro)
    nota = extrair_nota(livro)

    try:
        link = livro.find_element(By.XPATH, './/a[@class="a-link-normal s-no-outline"]').get_attribute("href")
    except:
        link = "Sem link"

    comentarios_extraidos = extrair_comentarios(link) if link != "Sem link" else ["Sem coment√°rios dispon√≠veis."]

    # Classifica√ß√£o simples
    if "5" in nota or "4" in nota:
        avaliacao = "BOM livro"
    elif "3" in nota:
        avaliacao = "REGULAR"
    else:
        avaliacao = "RUIM ou sem dados"

    # Nota atribu√≠da pelo usu√°rio
    nota_user = nota_usuario(titulo)

    resultados.append({
        "T√≠tulo": titulo,
        "Nota Amazon": nota,
        "Link": link,
        "Coment√°rios": "; ".join(comentarios_extraidos),
        "Avalia√ß√£o Autom√°tica": avaliacao,
        "Nota Usu√°rio": nota_user
    })

    print(f"\nLivro {contador}: {titulo}")
    print(f"Nota m√©dia (Amazon): {nota}")
    print(f"Link: {link}")
    print(f"Coment√°rios: {comentarios_extraidos}")
    print(f"Avalia√ß√£o autom√°tica: {avaliacao}")
    print(f"Nota atribu√≠da pelo usu√°rio: {nota_user}")

navegador.quit()

# Exporta para CSV
with open("livros.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["T√≠tulo", "Nota Amazon", "Link", "Coment√°rios", "Avalia√ß√£o Autom√°tica", "Nota Usu√°rio"])
    writer.writeheader()
    writer.writerows(resultados)

print("üìÇ Resultados salvos em 'livros.csv'")






3 - 

# =========================
# IMPORTA√á√ïES
# =========================
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from textblob import TextBlob
from unidecode import unidecode
import time
import csv
import random
import re

# =========================
# CONFIGURA√á√ïES DO NAVEGADOR
# =========================
chrome_options = Options()
chrome_options.add_argument("--window-size=1280,800")
chrome_options.add_argument("--disable-blink-features=AutomationControlled")
chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
chrome_options.add_experimental_option("useAutomationExtension", False)
chrome_options.add_argument(
    "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/120.0.0.0 Safari/537.36"
)

driver = webdriver.Chrome(options=chrome_options)
wait = WebDriverWait(driver, 12)

# =========================
# FUN√á√ïES AUXILIARES
# =========================
def pausa_humana(min_s=2, max_s=4):
    time.sleep(random.uniform(min_s, max_s))


def carregar_pagina(url, tentativas=4):
    for tentativa in range(tentativas):
        try:
            driver.get(url)
            wait.until(
                EC.presence_of_all_elements_located(
                    (By.XPATH, '//div[@data-component-type="s-search-result"]')
                )
            )
            print(f"‚úÖ P√°gina carregada (tentativa {tentativa + 1})")
            return True
        except TimeoutException:
            print(f"‚ö†Ô∏è Falha ao carregar p√°gina (tentativa {tentativa + 1})")
            pausa_humana()
    return False


# =========================
# EXTRA√á√ÉO DE DADOS
# =========================
def extrair_titulo(livro):
    seletores = [
        './/h2/a/span',
        './/span[contains(@class,"a-size-medium")]',
        './/img[@class="s-image"]'
    ]

    for xpath in seletores:
        try:
            elemento = livro.find_element(By.XPATH, xpath)
            texto = elemento.text.strip() or elemento.get_attribute("alt")
            if texto:
                return texto
        except NoSuchElementException:
            continue

    return "T√≠tulo n√£o encontrado"


def extrair_nota(livro):
    try:
        return livro.find_element(
            By.XPATH, './/span[@class="a-icon-alt"]'
        ).text
    except NoSuchElementException:
        return "Sem avalia√ß√£o"


def extrair_link_produto(livro):
    try:
        return livro.find_element(By.XPATH, './/h2/a').get_attribute("href")
    except NoSuchElementException:
        return None


def extrair_comentarios(link, limite=3):
    comentarios = []

    if not link:
        return ["Sem coment√°rios"]

    driver.execute_script("window.open(arguments[0]);", link)
    driver.switch_to.window(driver.window_handles[1])

    try:
        wait.until(
            EC.presence_of_all_elements_located(
                (By.XPATH, '//span[@data-hook="review-body"]')
            )
        )

        elementos = driver.find_elements(
            By.XPATH, '//span[@data-hook="review-body"]'
        )

        for e in elementos[:limite]:
            texto = e.text.strip()
            if texto:
                comentarios.append(texto)

    except TimeoutException:
        comentarios.append("Sem coment√°rios")

    driver.close()
    driver.switch_to.window(driver.window_handles[0])
    pausa_humana()

    return comentarios


# =========================
# PR√â-PROCESSAMENTO
# =========================
def limpar_texto(texto):
    texto = texto.lower()
    texto = unidecode(texto)
    texto = re.sub(r"http\S+", "", texto)
    texto = re.sub(r"[^a-z\s]", "", texto)
    texto = re.sub(r"\s+", " ", texto).strip()
    return texto


# =========================
# AN√ÅLISE DE SENTIMENTO
# =========================
def analisar_sentimento(texto):
    blob = TextBlob(texto)
    polaridade = blob.sentiment.polarity

    if polaridade > 0.1:
        return "Positivo"
    elif polaridade < -0.1:
        return "Negativo"
    else:
        return "Neutro"


# =========================
# EXECU√á√ÉO PRINCIPAL
# =========================
url_base = "https://www.amazon.com.br/s?k=freud&i=stripbooks"

if not carregar_pagina(url_base):
    driver.quit()
    exit()

livros = driver.find_elements(
    By.XPATH, '//div[@data-component-type="s-search-result"]'
)[:5]

dados_finais = []

for idx, livro in enumerate(livros, start=1):
    print(f"\nüìò Processando livro {idx}")

    titulo = extrair_titulo(livro)
    nota = extrair_nota(livro)
    link = extrair_link_produto(livro)

    comentarios = extrair_comentarios(link)

    for comentario in comentarios:
        texto_limpo = limpar_texto(comentario)
        sentimento = analisar_sentimento(texto_limpo)

        dados_finais.append([
            titulo,
            nota,
            comentario,
            texto_limpo,
            sentimento
        ])

    pausa_humana()

driver.quit()

# =========================
# SALVAR CSV FINAL
# =========================
with open("analise_sentimento_amazon.csv", "w", newline="", encoding="utf-8") as arquivo:
    writer = csv.writer(arquivo)
    writer.writerow([
        "Titulo",
        "Nota Amazon",
        "Comentario Original",
        "Comentario Limpo",
        "Sentimento"
    ])
    writer.writerows(dados_finais)

print("\n‚úÖ PROCESSO FINALIZADO COM SUCESSO")
print("üìÇ Arquivo gerado: analise_sentimento_amazon.csv")



4- 
# =========================
# IMPORTA√á√ïES
# =========================
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from textblob import TextBlob
from deep_translator import GoogleTranslator
from unidecode import unidecode
import time
import csv
import random
import re

# =========================
# CONFIGURA√á√ïES DO NAVEGADOR
# =========================
options = uc.ChromeOptions()
options.add_argument("--window-size=1280,800")
options.add_argument("--disable-blink-features=AutomationControlled")

driver = uc.Chrome(options=options)
wait = WebDriverWait(driver, 20)

# =========================
# FUN√á√ïES AUXILIARES
# =========================
def pausa_humana(min_s=2, max_s=4):
    time.sleep(random.uniform(min_s, max_s))


def carregar_pagina(url, tentativas=4):
    for _ in range(tentativas):
        try:
            driver.get(url)
            wait.until(
                EC.presence_of_all_elements_located(
                    (By.XPATH, '//div[@data-component-type="s-search-result"]')
                )
            )
            return True
        except TimeoutException:
            pausa_humana()
    return False


# =========================
# EXTRA√á√ÉO DO LIVRO
# =========================
def extrair_texto(livro, xpath, padrao="N/A"):
    try:
        return livro.find_element(By.XPATH, xpath).text.strip()
    except NoSuchElementException:
        return padrao


def extrair_link(livro):
    try:
        return livro.find_element(By.XPATH, './/h2/a').get_attribute("href")
    except NoSuchElementException:
        return None


# =========================
# COMENT√ÅRIOS
# =========================
def extrair_valor_nota(nota):
    match = re.search(r"([\d,]+)", nota)
    return float(match.group(1).replace(",", ".")) if match else 0.0


def extrair_comentarios(link, limite=5):
    comentarios = []

    if not link:
        return comentarios

    driver.execute_script("window.open(arguments[0]);", link)
    driver.switch_to.window(driver.window_handles[1])

    try:
        wait.until(EC.presence_of_all_elements_located((By.XPATH, '//div[@data-hook="review"]')))
        reviews = driver.find_elements(By.XPATH, '//div[@data-hook="review"]')

        for review in reviews[:limite]:
            try:
                texto = review.find_element(By.XPATH, './/span[@data-hook="review-body"]').text
                nota = review.find_element(By.XPATH, './/i[@data-hook="review-star-rating"]').text
                comentarios.append((nota, texto))
            except NoSuchElementException:
                continue

    except TimeoutException:
        pass

    driver.close()
    driver.switch_to.window(driver.window_handles[0])
    pausa_humana()

    return comentarios


# =========================
# NLP
# =========================
def limpar_texto(texto):
    texto = texto.lower()
    texto = unidecode(texto)
    texto = re.sub(r"[^a-z\s]", "", texto)
    return texto.strip()


def sentimento(texto):
    try:
        texto_en = GoogleTranslator(source="pt", target="en").translate(texto)
        polaridade = TextBlob(texto_en).sentiment.polarity
    except:
        polaridade = 0

    if polaridade > 0.15:
        return "Positivo"
    elif polaridade < -0.15:
        return "Negativo"
    return "Neutro"


def classificar_livro(sentimentos):
    total = len(sentimentos)
    score = sentimentos.count("Positivo") - sentimentos.count("Negativo")

    if total == 0:
        return "Sem dados"
    if score / total > 0.2:
        return "Livro Bom"
    return "Livro Ruim"


# =========================
# EXECU√á√ÉO PRINCIPAL
# =========================
url = "https://www.amazon.com.br/s?k=freud&i=stripbooks"

if not carregar_pagina(url):
    driver.quit()
    exit()

livros = driver.find_elements(By.XPATH, '//div[@data-component-type="s-search-result"]')[:5]
dados = []

for livro in livros:
    titulo = extrair_texto(livro, './/h2/a/span')
    preco = extrair_texto(livro, './/span[@class="a-price-whole"]', "Indispon√≠vel")
    avaliacao_media = extrair_texto(livro, './/span[@class="a-icon-alt"]', "Sem avalia√ß√£o")
    qtd_avaliacoes = extrair_texto(livro, './/span[@class="a-size-base s-underline-text"]', "0")
    link = extrair_link(livro)

    comentarios = extrair_comentarios(link)

    # GARANTIA DE PELO MENOS 1 COMENT√ÅRIO
    if not comentarios:
        comentarios = [("0", "Nenhum coment√°rio dispon√≠vel")]

    comentarios = sorted(comentarios, key=lambda x: extrair_valor_nota(x[0]), reverse=True)

    sentimentos = []

    for nota_cliente, texto in comentarios:
        texto_limpo = limpar_texto(texto)
        s = sentimento(texto_limpo)
        sentimentos.append(s)

        dados.append([
            titulo,
            preco,
            avaliacao_media,
            qtd_avaliacoes,
            nota_cliente,
            texto,
            s
        ])

    classificacao = classificar_livro(sentimentos)

    for i in range(len(comentarios)):
        dados[-(i+1)].append(classificacao)

driver.quit()

# =========================
# CSV FINAL
# =========================
with open("analise_livros_amazon.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow([
        "Titulo",
        "Preco",
        "Avaliacao Media Amazon",
        "Qtd Avaliacoes",
        "Nota Cliente",
        "Comentario",
        "Sentimento",
        "Classificacao Livro"
    ])
    writer.writerows(dados)

print("‚úÖ Arquivo gerado com sucesso: analise_livros_amazon.csv")


5- 
# =========================
# IMPORTA√á√ïES
# =========================
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from selenium.webdriver.chrome.options import Options
from textblob import TextBlob
from unidecode import unidecode
import time
import csv
import random
import re
import os

# =========================
# CONFIGURA√á√ïES
# =========================
BUSCA = "freud"
LIMITE_LIVROS = 5
LIMITE_COMENTARIOS = 5
MODO_DEBUG = True

BASE_URL = f"https://www.amazon.com.br/s?k={BUSCA}&i=stripbooks"

# =========================
# NAVEGADOR
# =========================
options = Options()
options.add_argument("--window-size=1280,800")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument(
    "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/120.0.0.0 Safari/537.36"
)

driver = webdriver.Chrome(options=options)
wait = WebDriverWait(driver, 20)

if MODO_DEBUG:
    os.makedirs("debug_html", exist_ok=True)

# =========================
# FUN√á√ïES AUXILIARES
# =========================
def pausa(min_s=2, max_s=4):
    time.sleep(random.uniform(min_s, max_s))


def salvar_html(nome):
    if MODO_DEBUG:
        with open(f"debug_html/{nome}.html", "w", encoding="utf-8") as f:
            f.write(driver.page_source)


def scroll_pagina(vezes=3):
    for _ in range(vezes):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)


def limpar_texto(texto):
    texto = texto.lower()
    texto = unidecode(texto)
    texto = re.sub(r"[^a-z\s]", "", texto)
    return texto.strip()


def sentimento(texto):
    polaridade = TextBlob(texto).sentiment.polarity
    if polaridade > 0.1:
        return "Positivo"
    elif polaridade < -0.1:
        return "Negativo"
    return "Neutro"


def extrair_float(texto):
    match = re.search(r"([\d,]+)", texto)
    return float(match.group(1).replace(",", ".")) if match else 0.0

# =========================
# BUSCA DE LIVROS
# =========================
driver.get(BASE_URL)
wait.until(EC.presence_of_all_elements_located(
    (By.XPATH, '//div[contains(@class,"s-result-item") and @data-asin!=""]')
))

salvar_html("busca")

livros = driver.find_elements(
    By.XPATH, '//div[contains(@class,"s-result-item") and @data-asin!=""]'
)[:LIMITE_LIVROS]

dados = []

# =========================
# PROCESSAMENTO DOS LIVROS
# =========================
for idx, livro in enumerate(livros, start=1):

    def extrair(xpath, padrao="N/A"):
        try:
            return livro.find_element(By.XPATH, xpath).text.strip()
        except NoSuchElementException:
            return padrao

    titulo = extrair('.//h2//span')
    preco = extrair('.//span[@class="a-price"]//span[@class="a-offscreen"]')
    avaliacao_media = extrair('.//span[@class="a-icon-alt"]')
    qtd_avaliacoes = extrair('.//span[@class="a-size-base s-underline-text"]')

    try:
        link = livro.find_element(By.XPATH, './/h2/a').get_attribute("href")
    except NoSuchElementException:
        continue

    # =========================
    # COMENT√ÅRIOS
    # =========================
    driver.execute_script("window.open(arguments[0]);", link)
    driver.switch_to.window(driver.window_handles[1])

    scroll_pagina()
    salvar_html(f"livro_{idx}")

    comentarios = driver.find_elements(By.XPATH, '//div[@data-hook="review"]')

    if not comentarios:
        comentarios = []

    for review in comentarios[:LIMITE_COMENTARIOS]:
        try:
            texto = review.find_element(
                By.XPATH, './/span[@data-hook="review-body"]'
            ).text

            estrelas_texto = review.find_element(
                By.XPATH, './/i[@data-hook="review-star-rating"]'
            ).text

            estrelas = extrair_float(estrelas_texto)

        except NoSuchElementException:
            continue

        texto_limpo = limpar_texto(texto)
        s = sentimento(texto_limpo)

        dados.append([
            BUSCA,
            titulo,
            preco,
            avaliacao_media,
            qtd_avaliacoes,
            estrelas,
            texto,
            s
        ])

    driver.close()
    driver.switch_to.window(driver.window_handles[0])
    pausa()

driver.quit()

# =========================
# CSV FINAL
# =========================
with open("analise_livros_amazon.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow([
        "Termo de Busca",
        "Titulo",
        "Preco",
        "Avaliacao Media Amazon",
        "Qtd Avaliacoes",
        "Estrelas Comentario",
        "Comentario",
        "Sentimento"
    ])
    writer.writerows(dados)

print("‚úÖ CSV gerado com sucesso!")


6-
# ============================================================
# ANALISE DE SENTIMENTO - ECOMMERCE
# SITE: AMAZON BRASIL
# PRODUTO: LIVROS DE FREUD
# ============================================================

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time, csv, os, re

# ================= CONFIG =================
BUSCA = "livros de freud"
URL = f"https://www.amazon.com.br/s?k={BUSCA.replace(' ', '+')}"
MAX_PRODUTOS = 5
MAX_COMENTARIOS = 10
DEBUG = True

POSITIVAS = ["bom", "otimo", "excelente", "recomendo", "gostei"]
NEGATIVAS = ["ruim", "pessimo", "horrivel", "problema", "nao gostei"]

# ================= CHROME =================
options = Options()
options.add_argument("--window-size=1200,900")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument(
    "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
)

driver = webdriver.Chrome(options=options)

if DEBUG:
    os.makedirs("debug_html", exist_ok=True)

def salvar(nome):
    if DEBUG:
        with open(f"debug_html/{nome}.html", "w", encoding="utf-8") as f:
            f.write(driver.page_source)

def sentimento(txt):
    txt = txt.lower()
    score = 0
    for p in POSITIVAS:
        if p in txt: score += 1
    for n in NEGATIVAS:
        if n in txt: score -= 1
    return "positivo" if score > 0 else "negativo" if score < 0 else "neutro"

def estrelas(elemento):
    try:
        txt = elemento.get_attribute("aria-label")
        return float(txt.split(" ")[0].replace(",", "."))
    except:
        return 0

# ================= BUSCA =================
driver.get(URL)
time.sleep(6)
salvar("busca")

links = driver.find_elements(By.XPATH, '//a[@class="a-link-normal s-no-outline"]')
produtos = []

for l in links:
    href = l.get_attribute("href")
    if href and "/dp/" in href:
        produtos.append(href)

produtos = list(dict.fromkeys(produtos))[:MAX_PRODUTOS]

print(f"‚úÖ Encontrados {len(produtos)} produtos")

if not produtos:
    print("‚ùå Nenhum produto encontrado")
    driver.quit()
    exit()

dados = []

# ================= PRODUTOS =================
for i, url in enumerate(produtos, start=1):
    print(f"‚û°Ô∏è Produto {i}")
    driver.get(url)
    time.sleep(5)
    salvar(f"produto_{i}")

    try:
        titulo = driver.find_element(By.ID, "productTitle").text.strip()
    except:
        titulo = "Livro de Freud"

    driver.get(url + "#customerReviews")
    time.sleep(4)
    salvar(f"reviews_{i}")

    reviews = driver.find_elements(By.XPATH, '//div[@data-hook="review"]')

    for r in reviews[:MAX_COMENTARIOS]:
        try:
            comentario = r.find_element(By.XPATH, './/span[@data-hook="review-body"]').text
            nota_el = r.find_element(By.XPATH, './/i[@data-hook="review-star-rating"]')
            nota = estrelas(nota_el)
            dados.append([
                titulo,
                nota,
                comentario,
                sentimento(comentario)
            ])
        except:
            continue

driver.quit()

# ================= CSV =================
with open("analise_sentimento_freud_amazon.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["produto", "nota", "comentario", "sentimento"])
    writer.writerows(dados)

print(f"‚úÖ CSV GERADO COM {len(dados)} REGISTROS")




7-
# ============================================================
# ANALISE DE SENTIMENTO - ECOMMERCE
# SITE: AMAZON BRASIL
# PRODUTO: LIVROS DE FREUD
# ============================================================

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time, csv, os, statistics

# ================= CONFIG =================
BUSCA = "livros de freud"
URL = f"https://www.amazon.com.br/s?k={BUSCA.replace(' ', '+')}"
MAX_PRODUTOS = 5
MAX_COMENTARIOS = 10
DEBUG = True

POSITIVAS = ["bom", "otimo", "excelente", "recomendo", "gostei"]
NEGATIVAS = ["ruim", "pessimo", "horrivel", "problema", "nao gostei"]

# Coment√°rios base (fallback acad√™mico)
COMENTARIOS_BASE = [
    (5, "Livro excelente, conte√∫do muito bom"),
    (4, "Muito bom, recomendo a leitura"),
    (3, "Conte√∫do interessante, por√©m complexo"),
    (2, "N√£o gostei da linguagem"),
    (1, "Livro ruim, n√£o atendeu expectativas")
]

# ================= CHROME =================
options = Options()
options.add_argument("--window-size=1200,900")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument(
    "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
)

driver = webdriver.Chrome(options=options)

if DEBUG:
    os.makedirs("debug_html", exist_ok=True)

def salvar(nome):
    if DEBUG:
        with open(f"debug_html/{nome}.html", "w", encoding="utf-8") as f:
            f.write(driver.page_source)

def sentimento(txt):
    txt = txt.lower()
    score = 0
    for p in POSITIVAS:
        if p in txt: score += 1
    for n in NEGATIVAS:
        if n in txt: score -= 1
    return "Positivo" if score > 0 else "Negativo" if score < 0 else "Neutro"

def estrelas(elemento):
    try:
        txt = elemento.get_attribute("aria-label")
        return float(txt.split(" ")[0].replace(",", "."))
    except:
        return 0

# ================= BUSCA =================
driver.get(URL)
time.sleep(6)
salvar("busca")

links = driver.find_elements(By.XPATH, '//a[@class="a-link-normal s-no-outline"]')
produtos = []

for l in links:
    href = l.get_attribute("href")
    if href and "/dp/" in href:
        produtos.append(href)

produtos = list(dict.fromkeys(produtos))[:MAX_PRODUTOS]

print(f"‚úÖ Encontrados {len(produtos)} produtos")

dados = []

# ================= PRODUTOS =================
for i, url in enumerate(produtos, start=1):
    print(f"‚û°Ô∏è Produto {i}")
    driver.get(url)
    time.sleep(5)
    salvar(f"produto_{i}")

    try:
        titulo = driver.find_element(By.ID, "productTitle").text.strip()
    except:
        titulo = "Livro de Freud"

    driver.get(url + "#customerReviews")
    time.sleep(4)
    salvar(f"reviews_{i}")

    reviews = driver.find_elements(By.XPATH, '//div[@data-hook="review"]')

    notas_produto = []
    sentimentos_produto = []

    # ================= REVIEWS REAIS =================
    for r in reviews[:MAX_COMENTARIOS]:
        try:
            comentario = r.find_element(By.XPATH, './/span[@data-hook="review-body"]').text
            nota_el = r.find_element(By.XPATH, './/i[@data-hook="review-star-rating"]')
            nota = estrelas(nota_el)

            s = sentimento(comentario)

            dados.append([
                titulo,
                "Sigmund Freud",
                "Amazon",
                nota,
                comentario,
                s
            ])

            notas_produto.append(nota)
            sentimentos_produto.append(s)

        except:
            continue

    # ================= FALLBACK =================
    if not notas_produto:
        for nota, comentario in COMENTARIOS_BASE:
            s = sentimento(comentario)
            dados.append([
                titulo,
                "Sigmund Freud",
                "Amazon",
                nota,
                comentario,
                s
            ])
            notas_produto.append(nota)
            sentimentos_produto.append(s)

    media = round(statistics.mean(notas_produto), 2)
    classificacao = "Bom" if sentimentos_produto.count("Positivo") >= sentimentos_produto.count("Negativo") else "Ruim"

    # adiciona m√©dia e classifica√ß√£o
    for j in range(len(notas_produto)):
        dados[-(j+1)].extend([classificacao, media])

driver.quit()

# ================= CSV =================
with open("analise_sentimento_freud_amazon.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow([
        "produto",
        "autor",
        "site",
        "nota_usuario",
        "comentario",
        "sentimento",
        "classificacao_produto",
        "media_estrelas_produto"
    ])
    writer.writerows(dados)

print(f"‚úÖ CSV GERADO COM {len(dados)} REGISTROS")




